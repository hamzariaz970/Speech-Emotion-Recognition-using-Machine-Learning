{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAVDESS Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9s/3d7b5lt55zggdrplnwwbsq_40000gp/T/ipykernel_73857/1553854669.py:99: FutureWarning: librosa.beat.tempo\n",
      "\tThis function was moved to 'librosa.feature.rhythm.tempo' in librosa version 0.10.0.\n",
      "\tThis alias will be removed in librosa version 1.0.\n",
      "  tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr).item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAVDESS feature extraction completed and dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Define target duration (in seconds) and sampling rate\n",
    "target_duration = 3.0  # in seconds\n",
    "target_sampling_rate = 22050  # in Hz\n",
    "\n",
    "# Unified emotion mapping\n",
    "emotion_mapping = {\n",
    "    \"neutral\": \"neutral\",\n",
    "    \"calm\": \"neutral\",\n",
    "    \"happy\": \"happy\",\n",
    "    \"sad\": \"sad\",\n",
    "    \"angry\": \"angry\",\n",
    "    \"fearful\": \"fearful\",\n",
    "    \"disgust\": \"disgust\",\n",
    "    \"surprised\": \"surprised\"\n",
    "}\n",
    "\n",
    "# Function to preprocess audio file to ensure consistent duration and sampling rate\n",
    "def preprocess_audio(audio_path):\n",
    "    audio, sr = librosa.load(audio_path, sr=target_sampling_rate)\n",
    "    target_length = int(target_duration * target_sampling_rate)\n",
    "\n",
    "    if len(audio) < target_length:\n",
    "        # Pad with zeros to reach the target length\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "    else:\n",
    "        # Truncate to the target length\n",
    "        audio = audio[:target_length]\n",
    "\n",
    "    return audio, target_sampling_rate\n",
    "\n",
    "# Function to extract features from a single audio file\n",
    "def extract_features(audio_path):\n",
    "    features = {}\n",
    "\n",
    "    # Preprocess the audio file\n",
    "    audio, sr = preprocess_audio(audio_path)\n",
    "\n",
    "    # --- Features from your notebook ---\n",
    "    FRAME_LENGTH = 1024\n",
    "    HOP_LENGTH = 512\n",
    "\n",
    "    # 1. RMSE\n",
    "    rms = librosa.feature.rms(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).mean()\n",
    "    features['RMSE'] = rms\n",
    "\n",
    "    # 2. Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).mean()\n",
    "    features['Zero_Crossing_Rate'] = zcr\n",
    "\n",
    "    # 3. Mel Spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH, n_mels=90)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec).mean()\n",
    "    features['Mel_Spectrogram_Mean'] = mel_spec_db\n",
    "\n",
    "    # 4. MFCCs and derivatives\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13, n_fft=1024, hop_length=HOP_LENGTH)\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "    features.update({f'MFCC_{i+1}': val for i, val in enumerate(mfccs_mean)})\n",
    "    features.update({f'Delta_MFCC_{i+1}': val for i, val in enumerate(delta_mfccs.mean(axis=1))})\n",
    "    features.update({f'Delta2_MFCC_{i+1}': val for i, val in enumerate(delta2_mfccs.mean(axis=1))})\n",
    "\n",
    "    # 5. Spectral Centroid\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Centroid'] = spectral_centroid\n",
    "\n",
    "    # 6. Spectral Bandwidth\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Bandwidth'] = spectral_bandwidth\n",
    "\n",
    "    # --- Additional Features ---\n",
    "    # 7. Pitch (Fundamental Frequency)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH)\n",
    "    pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0\n",
    "    features['Pitch_Mean'] = pitch_mean\n",
    "\n",
    "    # 8. Harmonic-to-Noise Ratio (HNR)\n",
    "    harmonic, percussive = librosa.effects.hpss(audio)\n",
    "    hnr = 10 * np.log10(np.mean(harmonic**2) / np.mean(percussive**2)) if np.mean(percussive**2) > 0 else 0\n",
    "    features['HNR'] = hnr\n",
    "\n",
    "    # 9. Spectral Contrast\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Contrast'] = spectral_contrast\n",
    "\n",
    "    # 10. Chroma Features\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean(axis=1)\n",
    "    features.update({f'Chroma_{i+1}': val for i, val in enumerate(chroma)})\n",
    "\n",
    "    # 11. Tempo (Rhythm)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr, hop_length=HOP_LENGTH)\n",
    "    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr).item()\n",
    "    features['Tempo'] = tempo\n",
    "\n",
    "    # 12. Jitter and Shimmer (Approximation)\n",
    "    jitter = np.std(np.diff(pitches[pitches > 0])) / pitch_mean if pitch_mean > 0 else 0\n",
    "    shimmer = np.std(np.abs(np.diff(audio))) / np.mean(np.abs(audio)) if np.mean(np.abs(audio)) > 0 else 0\n",
    "    features['Jitter'] = jitter\n",
    "    features['Shimmer'] = shimmer\n",
    "\n",
    "    # 13. Tonality and Timbre\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=audio).mean()\n",
    "    features['Spectral_Flatness'] = spectral_flatness\n",
    "\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Rolloff'] = spectral_rolloff\n",
    "\n",
    "    # 14. Duration and Silence\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "    silence = np.mean(audio == 0)\n",
    "    features['Duration'] = duration\n",
    "    features['Silence'] = silence\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to process all audio files in the RAVDESS dataset\n",
    "def process_ravdess(dataset_path):\n",
    "    data = []\n",
    "\n",
    "    raw_emotion_mapping = {\n",
    "        \"01\": \"neutral\",\n",
    "        \"02\": \"calm\",\n",
    "        \"03\": \"happy\",\n",
    "        \"04\": \"sad\",\n",
    "        \"05\": \"angry\",\n",
    "        \"06\": \"fearful\",\n",
    "        \"07\": \"disgust\",\n",
    "        \"08\": \"surprised\"\n",
    "    }\n",
    "\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Extract emotion from filename\n",
    "                file_parts = file.split('-')\n",
    "                emotion_code = file_parts[2]\n",
    "                raw_emotion = raw_emotion_mapping.get(emotion_code, \"unknown\")\n",
    "                emotion = emotion_mapping.get(raw_emotion, \"unknown\")\n",
    "\n",
    "                features = extract_features(file_path)\n",
    "                features['Emotion'] = emotion\n",
    "                data.append(features)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Path to RAVDESS dataset\n",
    "dataset_path = \"Dataset/RAVDESS\"\n",
    "ravdess_dataset = process_ravdess(dataset_path)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "ravdess_dataset.to_csv(\"Dataset/RAVDESS_features_dataset.csv\", index=False)\n",
    "\n",
    "print(\"RAVDESS feature extraction completed and dataset saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RMSE  Zero_Crossing_Rate  Mel_Spectrogram_Mean     MFCC_1     MFCC_2  \\\n",
      "0  0.014747            0.181806            -49.928920 -565.68760  43.782420   \n",
      "1  0.010142            0.164250            -53.197456 -605.44180  45.174736   \n",
      "2  0.047152            0.237027            -38.741500 -443.21610  24.900938   \n",
      "3  0.030824            0.148445            -41.572445 -473.73538  44.729717   \n",
      "4  0.005151            0.137492            -58.592377 -663.29486  60.307990   \n",
      "\n",
      "      MFCC_3    MFCC_4     MFCC_5     MFCC_6     MFCC_7  ...  Chroma_11  \\\n",
      "0  -3.419823  4.879561 -11.828972  -7.854157 -10.851251  ...   0.356888   \n",
      "1  -5.537606  6.142505  -2.014863 -10.605732 -15.667695  ...   0.345317   \n",
      "2 -30.117960  0.428244 -11.970781 -20.010164 -16.112022  ...   0.492545   \n",
      "3 -10.718471  6.005490 -12.931274 -14.678432  -5.036605  ...   0.286623   \n",
      "4   1.032603  9.540112  -6.581423  -2.948161 -10.793342  ...   0.264617   \n",
      "\n",
      "   Chroma_12       Tempo    Jitter   Shimmer  Spectral_Flatness  \\\n",
      "0   0.346651  123.046875  0.006238  1.162623           0.248231   \n",
      "1   0.357653  103.359375  0.006066  0.915142           0.306430   \n",
      "2   0.463739  123.046875  0.004500  0.618952           0.068761   \n",
      "3   0.297752  123.046875  0.005488  0.827023           0.231424   \n",
      "4   0.308694  135.999178  0.006102  0.933911           0.316868   \n",
      "\n",
      "   Spectral_Rolloff  Duration   Silence  Emotion  \n",
      "0       4459.857647       3.0  0.177989    angry  \n",
      "1       3734.354342       3.0  0.256070  fearful  \n",
      "2       5455.354192       3.0  0.000000  fearful  \n",
      "3       3929.312650       3.0  0.189327    angry  \n",
      "4       3486.059946       3.0  0.267196  disgust  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2880 entries, 0 to 2879\n",
      "Data columns (total 67 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   RMSE                  2880 non-null   float64\n",
      " 1   Zero_Crossing_Rate    2880 non-null   float64\n",
      " 2   Mel_Spectrogram_Mean  2880 non-null   float64\n",
      " 3   MFCC_1                2880 non-null   float64\n",
      " 4   MFCC_2                2880 non-null   float64\n",
      " 5   MFCC_3                2880 non-null   float64\n",
      " 6   MFCC_4                2880 non-null   float64\n",
      " 7   MFCC_5                2880 non-null   float64\n",
      " 8   MFCC_6                2880 non-null   float64\n",
      " 9   MFCC_7                2880 non-null   float64\n",
      " 10  MFCC_8                2880 non-null   float64\n",
      " 11  MFCC_9                2880 non-null   float64\n",
      " 12  MFCC_10               2880 non-null   float64\n",
      " 13  MFCC_11               2880 non-null   float64\n",
      " 14  MFCC_12               2880 non-null   float64\n",
      " 15  MFCC_13               2880 non-null   float64\n",
      " 16  Delta_MFCC_1          2880 non-null   float64\n",
      " 17  Delta_MFCC_2          2880 non-null   float64\n",
      " 18  Delta_MFCC_3          2880 non-null   float64\n",
      " 19  Delta_MFCC_4          2880 non-null   float64\n",
      " 20  Delta_MFCC_5          2880 non-null   float64\n",
      " 21  Delta_MFCC_6          2880 non-null   float64\n",
      " 22  Delta_MFCC_7          2880 non-null   float64\n",
      " 23  Delta_MFCC_8          2880 non-null   float64\n",
      " 24  Delta_MFCC_9          2880 non-null   float64\n",
      " 25  Delta_MFCC_10         2880 non-null   float64\n",
      " 26  Delta_MFCC_11         2880 non-null   float64\n",
      " 27  Delta_MFCC_12         2880 non-null   float64\n",
      " 28  Delta_MFCC_13         2880 non-null   float64\n",
      " 29  Delta2_MFCC_1         2880 non-null   float64\n",
      " 30  Delta2_MFCC_2         2880 non-null   float64\n",
      " 31  Delta2_MFCC_3         2880 non-null   float64\n",
      " 32  Delta2_MFCC_4         2880 non-null   float64\n",
      " 33  Delta2_MFCC_5         2880 non-null   float64\n",
      " 34  Delta2_MFCC_6         2880 non-null   float64\n",
      " 35  Delta2_MFCC_7         2880 non-null   float64\n",
      " 36  Delta2_MFCC_8         2880 non-null   float64\n",
      " 37  Delta2_MFCC_9         2880 non-null   float64\n",
      " 38  Delta2_MFCC_10        2880 non-null   float64\n",
      " 39  Delta2_MFCC_11        2880 non-null   float64\n",
      " 40  Delta2_MFCC_12        2880 non-null   float64\n",
      " 41  Delta2_MFCC_13        2880 non-null   float64\n",
      " 42  Spectral_Centroid     2880 non-null   float64\n",
      " 43  Spectral_Bandwidth    2880 non-null   float64\n",
      " 44  Pitch_Mean            2880 non-null   float64\n",
      " 45  HNR                   2880 non-null   float64\n",
      " 46  Spectral_Contrast     2880 non-null   float64\n",
      " 47  Chroma_1              2880 non-null   float64\n",
      " 48  Chroma_2              2880 non-null   float64\n",
      " 49  Chroma_3              2880 non-null   float64\n",
      " 50  Chroma_4              2880 non-null   float64\n",
      " 51  Chroma_5              2880 non-null   float64\n",
      " 52  Chroma_6              2880 non-null   float64\n",
      " 53  Chroma_7              2880 non-null   float64\n",
      " 54  Chroma_8              2880 non-null   float64\n",
      " 55  Chroma_9              2880 non-null   float64\n",
      " 56  Chroma_10             2880 non-null   float64\n",
      " 57  Chroma_11             2880 non-null   float64\n",
      " 58  Chroma_12             2880 non-null   float64\n",
      " 59  Tempo                 2880 non-null   float64\n",
      " 60  Jitter                2880 non-null   float64\n",
      " 61  Shimmer               2880 non-null   float64\n",
      " 62  Spectral_Flatness     2880 non-null   float64\n",
      " 63  Spectral_Rolloff      2880 non-null   float64\n",
      " 64  Duration              2880 non-null   float64\n",
      " 65  Silence               2880 non-null   float64\n",
      " 66  Emotion               2880 non-null   object \n",
      "dtypes: float64(66), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "ravdess_dataset_path = 'Dataset/RAVDESS_features_dataset.csv'  # Replace with your file path\n",
    "ravdess_dataset = pd.read_csv(ravdess_dataset_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(ravdess_dataset.head())\n",
    "\n",
    "# Check the dataset's structure\n",
    "print(ravdess_dataset.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE                    0\n",
      "Zero_Crossing_Rate      0\n",
      "Mel_Spectrogram_Mean    0\n",
      "MFCC_1                  0\n",
      "MFCC_2                  0\n",
      "                       ..\n",
      "Spectral_Flatness       0\n",
      "Spectral_Rolloff        0\n",
      "Duration                0\n",
      "Silence                 0\n",
      "Emotion                 0\n",
      "Length: 67, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2880, 67)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(ravdess_dataset.isnull().sum())\n",
    "ravdess_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESS Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9s/3d7b5lt55zggdrplnwwbsq_40000gp/T/ipykernel_73857/999054568.py:99: FutureWarning: librosa.beat.tempo\n",
      "\tThis function was moved to 'librosa.feature.rhythm.tempo' in librosa version 0.10.0.\n",
      "\tThis alias will be removed in librosa version 1.0.\n",
      "  tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr).item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESS feature extraction completed and dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Define target duration (in seconds) and sampling rate\n",
    "target_duration = 3.0  # in seconds\n",
    "target_sampling_rate = 22050  # in Hz\n",
    "\n",
    "# Unified emotion mapping\n",
    "emotion_mapping = {\n",
    "    \"neutral\": \"neutral\",\n",
    "    \"calm\": \"neutral\",\n",
    "    \"happy\": \"happy\",\n",
    "    \"sad\": \"sad\",\n",
    "    \"angry\": \"angry\",\n",
    "    \"fearful\": \"fearful\",\n",
    "    \"disgust\": \"disgust\",\n",
    "    \"surprised\": \"surprised\"\n",
    "}\n",
    "\n",
    "# Function to preprocess audio file to ensure consistent duration and sampling rate\n",
    "def preprocess_audio(audio_path):\n",
    "    audio, sr = librosa.load(audio_path, sr=target_sampling_rate)\n",
    "    target_length = int(target_duration * target_sampling_rate)\n",
    "\n",
    "    if len(audio) < target_length:\n",
    "        # Pad with zeros to reach the target length\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "    else:\n",
    "        # Truncate to the target length\n",
    "        audio = audio[:target_length]\n",
    "\n",
    "    return audio, target_sampling_rate\n",
    "\n",
    "# Function to extract features from a single audio file\n",
    "def extract_features(audio_path):\n",
    "    features = {}\n",
    "\n",
    "    # Preprocess the audio file\n",
    "    audio, sr = preprocess_audio(audio_path)\n",
    "\n",
    "    # --- Features from your notebook ---\n",
    "    FRAME_LENGTH = 1024\n",
    "    HOP_LENGTH = 512\n",
    "\n",
    "    # 1. RMSE\n",
    "    rms = librosa.feature.rms(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).mean()\n",
    "    features['RMSE'] = rms\n",
    "\n",
    "    # 2. Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).mean()\n",
    "    features['Zero_Crossing_Rate'] = zcr\n",
    "\n",
    "    # 3. Mel Spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH, n_mels=90)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec).mean()\n",
    "    features['Mel_Spectrogram_Mean'] = mel_spec_db\n",
    "\n",
    "    # 4. MFCCs and derivatives\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13, n_fft=1024, hop_length=HOP_LENGTH)\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "    features.update({f'MFCC_{i+1}': val for i, val in enumerate(mfccs_mean)})\n",
    "    features.update({f'Delta_MFCC_{i+1}': val for i, val in enumerate(delta_mfccs.mean(axis=1))})\n",
    "    features.update({f'Delta2_MFCC_{i+1}': val for i, val in enumerate(delta2_mfccs.mean(axis=1))})\n",
    "\n",
    "    # 5. Spectral Centroid\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Centroid'] = spectral_centroid\n",
    "\n",
    "    # 6. Spectral Bandwidth\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Bandwidth'] = spectral_bandwidth\n",
    "\n",
    "    # --- Additional Features ---\n",
    "    # 7. Pitch (Fundamental Frequency)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH)\n",
    "    pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0\n",
    "    features['Pitch_Mean'] = pitch_mean\n",
    "\n",
    "    # 8. Harmonic-to-Noise Ratio (HNR)\n",
    "    harmonic, percussive = librosa.effects.hpss(audio)\n",
    "    hnr = 10 * np.log10(np.mean(harmonic**2) / np.mean(percussive**2)) if np.mean(percussive**2) > 0 else 0\n",
    "    features['HNR'] = hnr\n",
    "\n",
    "    # 9. Spectral Contrast\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Contrast'] = spectral_contrast\n",
    "\n",
    "    # 10. Chroma Features\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean(axis=1)\n",
    "    features.update({f'Chroma_{i+1}': val for i, val in enumerate(chroma)})\n",
    "\n",
    "    # 11. Tempo (Rhythm)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr, hop_length=HOP_LENGTH)\n",
    "    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr).item()\n",
    "    features['Tempo'] = tempo\n",
    "\n",
    "    # 12. Jitter and Shimmer (Approximation)\n",
    "    jitter = np.std(np.diff(pitches[pitches > 0])) / pitch_mean if pitch_mean > 0 else 0\n",
    "    shimmer = np.std(np.abs(np.diff(audio))) / np.mean(np.abs(audio)) if np.mean(np.abs(audio)) > 0 else 0\n",
    "    features['Jitter'] = jitter\n",
    "    features['Shimmer'] = shimmer\n",
    "\n",
    "    # 13. Tonality and Timbre\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=audio).mean()\n",
    "    features['Spectral_Flatness'] = spectral_flatness\n",
    "\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Rolloff'] = spectral_rolloff\n",
    "\n",
    "    # 14. Duration and Silence\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "    silence = np.mean(audio == 0)\n",
    "    features['Duration'] = duration\n",
    "    features['Silence'] = silence\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to process all audio files in the TESS dataset\n",
    "def process_tess(dataset_path):\n",
    "    data = []\n",
    "\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Extract emotion from filename (e.g., \"OAF_back_angry.wav\")\n",
    "                emotion_raw = file.split('_')[-1].split('.')[0]  # Get the last part before .wav\n",
    "                emotion = emotion_mapping.get(emotion_raw.lower(), \"unknown\")\n",
    "\n",
    "                features = extract_features(file_path)\n",
    "                features['Emotion'] = emotion\n",
    "                data.append(features)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Path to TESS dataset\n",
    "dataset_path = \"Dataset/TESS\"\n",
    "tess_dataset = process_tess(dataset_path)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "tess_dataset.to_csv(\"Dataset/TESS_features_dataset.csv\", index=False)\n",
    "\n",
    "print(\"TESS feature extraction completed and dataset saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RMSE  Zero_Crossing_Rate  Mel_Spectrogram_Mean     MFCC_1     MFCC_2  \\\n",
      "0  0.012297            0.156393            -50.361750 -573.77203  43.899857   \n",
      "1  0.017376            0.129087            -47.293182 -538.34050  60.010815   \n",
      "2  0.018511            0.197994            -45.697884 -523.14594  55.392982   \n",
      "3  0.012757            0.167969            -49.176210 -560.29030  41.832100   \n",
      "4  0.021586            0.128403            -46.906307 -530.83180  66.517960   \n",
      "\n",
      "      MFCC_3     MFCC_4    MFCC_5    MFCC_6    MFCC_7  ...  Chroma_11  \\\n",
      "0   4.228216  29.829117 -3.161358 -4.192998 -5.612931  ...   0.308867   \n",
      "1  -3.632375  13.105334 -3.761131 -7.761571 -9.315113  ...   0.315968   \n",
      "2  11.233569  16.927362 -2.280778 -7.342680 -8.059875  ...   0.299951   \n",
      "3   1.466254  27.888405 -6.716061  0.907265 -9.043744  ...   0.340164   \n",
      "4  13.794174   3.213084 -3.236690 -0.956316 -6.556373  ...   0.278320   \n",
      "\n",
      "   Chroma_12       Tempo    Jitter   Shimmer  Spectral_Flatness  \\\n",
      "0   0.327924   95.703125  0.006806  0.897336           0.220625   \n",
      "1   0.344050   99.384014  0.007677  0.631812           0.229652   \n",
      "2   0.293882  161.499023  0.008812  0.715083           0.128458   \n",
      "3   0.385021  103.359375  0.005667  0.877936           0.169750   \n",
      "4   0.307933  151.999081  0.012449  0.567991           0.190634   \n",
      "\n",
      "   Spectral_Rolloff  Duration   Silence  Emotion  \n",
      "0       4086.173753       3.0  0.206410  disgust  \n",
      "1       3400.258413       3.0  0.226092  disgust  \n",
      "2       4232.102614       3.0  0.117974  disgust  \n",
      "3       4305.481145       3.0  0.152517  disgust  \n",
      "4       3531.942233       3.0  0.183749  disgust  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5600 entries, 0 to 5599\n",
      "Data columns (total 67 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   RMSE                  5600 non-null   float64\n",
      " 1   Zero_Crossing_Rate    5600 non-null   float64\n",
      " 2   Mel_Spectrogram_Mean  5600 non-null   float64\n",
      " 3   MFCC_1                5600 non-null   float64\n",
      " 4   MFCC_2                5600 non-null   float64\n",
      " 5   MFCC_3                5600 non-null   float64\n",
      " 6   MFCC_4                5600 non-null   float64\n",
      " 7   MFCC_5                5600 non-null   float64\n",
      " 8   MFCC_6                5600 non-null   float64\n",
      " 9   MFCC_7                5600 non-null   float64\n",
      " 10  MFCC_8                5600 non-null   float64\n",
      " 11  MFCC_9                5600 non-null   float64\n",
      " 12  MFCC_10               5600 non-null   float64\n",
      " 13  MFCC_11               5600 non-null   float64\n",
      " 14  MFCC_12               5600 non-null   float64\n",
      " 15  MFCC_13               5600 non-null   float64\n",
      " 16  Delta_MFCC_1          5600 non-null   float64\n",
      " 17  Delta_MFCC_2          5600 non-null   float64\n",
      " 18  Delta_MFCC_3          5600 non-null   float64\n",
      " 19  Delta_MFCC_4          5600 non-null   float64\n",
      " 20  Delta_MFCC_5          5600 non-null   float64\n",
      " 21  Delta_MFCC_6          5600 non-null   float64\n",
      " 22  Delta_MFCC_7          5600 non-null   float64\n",
      " 23  Delta_MFCC_8          5600 non-null   float64\n",
      " 24  Delta_MFCC_9          5600 non-null   float64\n",
      " 25  Delta_MFCC_10         5600 non-null   float64\n",
      " 26  Delta_MFCC_11         5600 non-null   float64\n",
      " 27  Delta_MFCC_12         5600 non-null   float64\n",
      " 28  Delta_MFCC_13         5600 non-null   float64\n",
      " 29  Delta2_MFCC_1         5600 non-null   float64\n",
      " 30  Delta2_MFCC_2         5600 non-null   float64\n",
      " 31  Delta2_MFCC_3         5600 non-null   float64\n",
      " 32  Delta2_MFCC_4         5600 non-null   float64\n",
      " 33  Delta2_MFCC_5         5600 non-null   float64\n",
      " 34  Delta2_MFCC_6         5600 non-null   float64\n",
      " 35  Delta2_MFCC_7         5600 non-null   float64\n",
      " 36  Delta2_MFCC_8         5600 non-null   float64\n",
      " 37  Delta2_MFCC_9         5600 non-null   float64\n",
      " 38  Delta2_MFCC_10        5600 non-null   float64\n",
      " 39  Delta2_MFCC_11        5600 non-null   float64\n",
      " 40  Delta2_MFCC_12        5600 non-null   float64\n",
      " 41  Delta2_MFCC_13        5600 non-null   float64\n",
      " 42  Spectral_Centroid     5600 non-null   float64\n",
      " 43  Spectral_Bandwidth    5600 non-null   float64\n",
      " 44  Pitch_Mean            5600 non-null   float64\n",
      " 45  HNR                   5600 non-null   float64\n",
      " 46  Spectral_Contrast     5600 non-null   float64\n",
      " 47  Chroma_1              5600 non-null   float64\n",
      " 48  Chroma_2              5600 non-null   float64\n",
      " 49  Chroma_3              5600 non-null   float64\n",
      " 50  Chroma_4              5600 non-null   float64\n",
      " 51  Chroma_5              5600 non-null   float64\n",
      " 52  Chroma_6              5600 non-null   float64\n",
      " 53  Chroma_7              5600 non-null   float64\n",
      " 54  Chroma_8              5600 non-null   float64\n",
      " 55  Chroma_9              5600 non-null   float64\n",
      " 56  Chroma_10             5600 non-null   float64\n",
      " 57  Chroma_11             5600 non-null   float64\n",
      " 58  Chroma_12             5600 non-null   float64\n",
      " 59  Tempo                 5600 non-null   float64\n",
      " 60  Jitter                5600 non-null   float64\n",
      " 61  Shimmer               5600 non-null   float64\n",
      " 62  Spectral_Flatness     5600 non-null   float64\n",
      " 63  Spectral_Rolloff      5600 non-null   float64\n",
      " 64  Duration              5600 non-null   float64\n",
      " 65  Silence               5600 non-null   float64\n",
      " 66  Emotion               5600 non-null   object \n",
      "dtypes: float64(66), object(1)\n",
      "memory usage: 2.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "tess_dataset_path = 'Dataset/TESS_features_dataset.csv'  # Replace with your file path\n",
    "tess_dataset = pd.read_csv(tess_dataset_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(tess_dataset.head())\n",
    "\n",
    "# Check the dataset's structure\n",
    "print(tess_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE                    0\n",
      "Zero_Crossing_Rate      0\n",
      "Mel_Spectrogram_Mean    0\n",
      "MFCC_1                  0\n",
      "MFCC_2                  0\n",
      "                       ..\n",
      "Spectral_Flatness       0\n",
      "Spectral_Rolloff        0\n",
      "Duration                0\n",
      "Silence                 0\n",
      "Emotion                 0\n",
      "Length: 67, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5600, 67)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(tess_dataset.isnull().sum())\n",
    "tess_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREMA-D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9s/3d7b5lt55zggdrplnwwbsq_40000gp/T/ipykernel_73857/2514050382.py:99: FutureWarning: librosa.beat.tempo\n",
      "\tThis function was moved to 'librosa.feature.rhythm.tempo' in librosa version 0.10.0.\n",
      "\tThis alias will be removed in librosa version 1.0.\n",
      "  tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr).item()\n",
      "/Users/hamzariaz/.pyenv/versions/3.10.6/lib/python3.10/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREMA-D feature extraction completed and dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Define target duration (in seconds) and sampling rate\n",
    "target_duration = 3.0  # in seconds\n",
    "target_sampling_rate = 22050  # in Hz\n",
    "\n",
    "# Unified emotion mapping\n",
    "emotion_mapping = {\n",
    "    \"neutral\": \"neutral\",\n",
    "    \"calm\": \"neutral\",\n",
    "    \"happy\": \"happy\",\n",
    "    \"sad\": \"sad\",\n",
    "    \"angry\": \"angry\",\n",
    "    \"fearful\": \"fearful\",\n",
    "    \"disgust\": \"disgust\",\n",
    "    \"surprised\": \"surprised\"\n",
    "}\n",
    "\n",
    "# Function to preprocess audio file to ensure consistent duration and sampling rate\n",
    "def preprocess_audio(audio_path):\n",
    "    audio, sr = librosa.load(audio_path, sr=target_sampling_rate)\n",
    "    target_length = int(target_duration * target_sampling_rate)\n",
    "\n",
    "    if len(audio) < target_length:\n",
    "        # Pad with zeros to reach the target length\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "    else:\n",
    "        # Truncate to the target length\n",
    "        audio = audio[:target_length]\n",
    "\n",
    "    return audio, target_sampling_rate\n",
    "\n",
    "# Function to extract features from a single audio file\n",
    "def extract_features(audio_path):\n",
    "    features = {}\n",
    "\n",
    "    # Preprocess the audio file\n",
    "    audio, sr = preprocess_audio(audio_path)\n",
    "\n",
    "    # --- Features from your notebook ---\n",
    "    FRAME_LENGTH = 1024\n",
    "    HOP_LENGTH = 512\n",
    "\n",
    "    # 1. RMSE\n",
    "    rms = librosa.feature.rms(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).mean()\n",
    "    features['RMSE'] = rms\n",
    "\n",
    "    # 2. Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).mean()\n",
    "    features['Zero_Crossing_Rate'] = zcr\n",
    "\n",
    "    # 3. Mel Spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH, n_mels=90)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec).mean()\n",
    "    features['Mel_Spectrogram_Mean'] = mel_spec_db\n",
    "\n",
    "    # 4. MFCCs and derivatives\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13, n_fft=1024, hop_length=HOP_LENGTH)\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "    features.update({f'MFCC_{i+1}': val for i, val in enumerate(mfccs_mean)})\n",
    "    features.update({f'Delta_MFCC_{i+1}': val for i, val in enumerate(delta_mfccs.mean(axis=1))})\n",
    "    features.update({f'Delta2_MFCC_{i+1}': val for i, val in enumerate(delta2_mfccs.mean(axis=1))})\n",
    "\n",
    "    # 5. Spectral Centroid\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Centroid'] = spectral_centroid\n",
    "\n",
    "    # 6. Spectral Bandwidth\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Bandwidth'] = spectral_bandwidth\n",
    "\n",
    "    # --- Additional Features ---\n",
    "    # 7. Pitch (Fundamental Frequency)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH)\n",
    "    pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0\n",
    "    features['Pitch_Mean'] = pitch_mean\n",
    "\n",
    "    # 8. Harmonic-to-Noise Ratio (HNR)\n",
    "    harmonic, percussive = librosa.effects.hpss(audio)\n",
    "    hnr = 10 * np.log10(np.mean(harmonic**2) / np.mean(percussive**2)) if np.mean(percussive**2) > 0 else 0\n",
    "    features['HNR'] = hnr\n",
    "\n",
    "    # 9. Spectral Contrast\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Contrast'] = spectral_contrast\n",
    "\n",
    "    # 10. Chroma Features\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean(axis=1)\n",
    "    features.update({f'Chroma_{i+1}': val for i, val in enumerate(chroma)})\n",
    "\n",
    "    # 11. Tempo (Rhythm)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr, hop_length=HOP_LENGTH)\n",
    "    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr).item()\n",
    "    features['Tempo'] = tempo\n",
    "\n",
    "    # 12. Jitter and Shimmer (Approximation)\n",
    "    jitter = np.std(np.diff(pitches[pitches > 0])) / pitch_mean if pitch_mean > 0 else 0\n",
    "    shimmer = np.std(np.abs(np.diff(audio))) / np.mean(np.abs(audio)) if np.mean(np.abs(audio)) > 0 else 0\n",
    "    features['Jitter'] = jitter\n",
    "    features['Shimmer'] = shimmer\n",
    "\n",
    "    # 13. Tonality and Timbre\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=audio).mean()\n",
    "    features['Spectral_Flatness'] = spectral_flatness\n",
    "\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Rolloff'] = spectral_rolloff\n",
    "\n",
    "    # 14. Duration and Silence\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "    silence = np.mean(audio == 0)\n",
    "    features['Duration'] = duration\n",
    "    features['Silence'] = silence\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to process all audio files in the CREMA-D dataset\n",
    "def process_crema_d(dataset_path):\n",
    "    data = []\n",
    "\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Extract emotion from filename (e.g., \"1001_DFA_ANG_XX.wav\")\n",
    "                file_parts = file.split('_')\n",
    "                raw_emotion_code = file_parts[2]\n",
    "                raw_emotion = {\n",
    "                    \"ANG\": \"angry\",\n",
    "                    \"DIS\": \"disgust\",\n",
    "                    \"FEA\": \"fearful\",\n",
    "                    \"HAP\": \"happy\",\n",
    "                    \"NEU\": \"neutral\",\n",
    "                    \"SAD\": \"sad\"\n",
    "                }.get(raw_emotion_code, \"unknown\")\n",
    "\n",
    "                emotion = emotion_mapping.get(raw_emotion, \"unknown\")\n",
    "\n",
    "                features = extract_features(file_path)\n",
    "                features['Emotion'] = emotion\n",
    "                data.append(features)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Path to CREMA-D dataset\n",
    "dataset_path = \"Dataset/CREMA-D\"\n",
    "crema_d_dataset = process_crema_d(dataset_path)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "crema_d_dataset.to_csv(\"Dataset/CREMA-D_features_dataset.csv\", index=False)\n",
    "\n",
    "print(\"CREMA-D feature extraction completed and dataset saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RMSE  Zero_Crossing_Rate  Mel_Spectrogram_Mean     MFCC_1      MFCC_2  \\\n",
      "0  0.073580            0.078305            -33.864310 -383.62805   85.888760   \n",
      "1  0.037229            0.091309            -37.033104 -423.04224  125.774460   \n",
      "2  0.007056            0.048941            -50.110780 -565.71550  111.819885   \n",
      "3  0.009229            0.051352            -48.222622 -545.74884  111.447610   \n",
      "4  0.014069            0.039776            -44.119440 -501.25912  130.523680   \n",
      "\n",
      "      MFCC_3     MFCC_4     MFCC_5     MFCC_6     MFCC_7  ...  Chroma_11  \\\n",
      "0   1.510415  38.184490  -2.107945  -2.918928 -12.555401  ...   0.373348   \n",
      "1  12.974215  51.769170 -17.094017  10.942081 -18.850365  ...   0.475053   \n",
      "2   2.412334  45.476185 -12.045537  21.651108 -13.544354  ...   0.488740   \n",
      "3  14.475146  46.292442 -11.371361  13.052764 -13.202646  ...   0.424008   \n",
      "4  15.468277  57.672870  -2.552489  15.085404  -6.516215  ...   0.547534   \n",
      "\n",
      "   Chroma_12       Tempo    Jitter   Shimmer  Spectral_Flatness  \\\n",
      "0   0.312333  123.046875  0.008603  0.701244           0.177074   \n",
      "1   0.508352  123.046875  0.016626  0.307142           0.000190   \n",
      "2   0.467947  172.265625  0.044836  0.284865           0.186921   \n",
      "3   0.412202  112.347147  0.037323  0.300089           0.177116   \n",
      "4   0.522979  143.554688  0.025948  0.284624           0.031516   \n",
      "\n",
      "   Spectral_Rolloff  Duration   Silence  Emotion  \n",
      "0       2655.540865       3.0  0.188088    angry  \n",
      "1       3278.016076       3.0  0.000000    angry  \n",
      "2       2516.403245       3.0  0.199214  neutral  \n",
      "3       2386.541466       3.0  0.188088  neutral  \n",
      "4       2478.802960       3.0  0.043477  disgust  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7442 entries, 0 to 7441\n",
      "Data columns (total 67 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   RMSE                  7442 non-null   float64\n",
      " 1   Zero_Crossing_Rate    7442 non-null   float64\n",
      " 2   Mel_Spectrogram_Mean  7442 non-null   float64\n",
      " 3   MFCC_1                7442 non-null   float64\n",
      " 4   MFCC_2                7442 non-null   float64\n",
      " 5   MFCC_3                7442 non-null   float64\n",
      " 6   MFCC_4                7442 non-null   float64\n",
      " 7   MFCC_5                7442 non-null   float64\n",
      " 8   MFCC_6                7442 non-null   float64\n",
      " 9   MFCC_7                7442 non-null   float64\n",
      " 10  MFCC_8                7442 non-null   float64\n",
      " 11  MFCC_9                7442 non-null   float64\n",
      " 12  MFCC_10               7442 non-null   float64\n",
      " 13  MFCC_11               7442 non-null   float64\n",
      " 14  MFCC_12               7442 non-null   float64\n",
      " 15  MFCC_13               7442 non-null   float64\n",
      " 16  Delta_MFCC_1          7442 non-null   float64\n",
      " 17  Delta_MFCC_2          7442 non-null   float64\n",
      " 18  Delta_MFCC_3          7442 non-null   float64\n",
      " 19  Delta_MFCC_4          7442 non-null   float64\n",
      " 20  Delta_MFCC_5          7442 non-null   float64\n",
      " 21  Delta_MFCC_6          7442 non-null   float64\n",
      " 22  Delta_MFCC_7          7442 non-null   float64\n",
      " 23  Delta_MFCC_8          7442 non-null   float64\n",
      " 24  Delta_MFCC_9          7442 non-null   float64\n",
      " 25  Delta_MFCC_10         7442 non-null   float64\n",
      " 26  Delta_MFCC_11         7442 non-null   float64\n",
      " 27  Delta_MFCC_12         7442 non-null   float64\n",
      " 28  Delta_MFCC_13         7442 non-null   float64\n",
      " 29  Delta2_MFCC_1         7442 non-null   float64\n",
      " 30  Delta2_MFCC_2         7442 non-null   float64\n",
      " 31  Delta2_MFCC_3         7442 non-null   float64\n",
      " 32  Delta2_MFCC_4         7442 non-null   float64\n",
      " 33  Delta2_MFCC_5         7442 non-null   float64\n",
      " 34  Delta2_MFCC_6         7442 non-null   float64\n",
      " 35  Delta2_MFCC_7         7442 non-null   float64\n",
      " 36  Delta2_MFCC_8         7442 non-null   float64\n",
      " 37  Delta2_MFCC_9         7442 non-null   float64\n",
      " 38  Delta2_MFCC_10        7442 non-null   float64\n",
      " 39  Delta2_MFCC_11        7442 non-null   float64\n",
      " 40  Delta2_MFCC_12        7442 non-null   float64\n",
      " 41  Delta2_MFCC_13        7442 non-null   float64\n",
      " 42  Spectral_Centroid     7442 non-null   float64\n",
      " 43  Spectral_Bandwidth    7442 non-null   float64\n",
      " 44  Pitch_Mean            7442 non-null   float64\n",
      " 45  HNR                   7442 non-null   float64\n",
      " 46  Spectral_Contrast     7442 non-null   float64\n",
      " 47  Chroma_1              7442 non-null   float64\n",
      " 48  Chroma_2              7442 non-null   float64\n",
      " 49  Chroma_3              7442 non-null   float64\n",
      " 50  Chroma_4              7442 non-null   float64\n",
      " 51  Chroma_5              7442 non-null   float64\n",
      " 52  Chroma_6              7442 non-null   float64\n",
      " 53  Chroma_7              7442 non-null   float64\n",
      " 54  Chroma_8              7442 non-null   float64\n",
      " 55  Chroma_9              7442 non-null   float64\n",
      " 56  Chroma_10             7442 non-null   float64\n",
      " 57  Chroma_11             7442 non-null   float64\n",
      " 58  Chroma_12             7442 non-null   float64\n",
      " 59  Tempo                 7442 non-null   float64\n",
      " 60  Jitter                7442 non-null   float64\n",
      " 61  Shimmer               7442 non-null   float64\n",
      " 62  Spectral_Flatness     7442 non-null   float64\n",
      " 63  Spectral_Rolloff      7442 non-null   float64\n",
      " 64  Duration              7442 non-null   float64\n",
      " 65  Silence               7442 non-null   float64\n",
      " 66  Emotion               7442 non-null   object \n",
      "dtypes: float64(66), object(1)\n",
      "memory usage: 3.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "crema_d_dataset_path = 'Dataset/CREMA-D_features_dataset.csv'  # Replace with your file path\n",
    "crema_d_dataset = pd.read_csv(crema_d_dataset_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(crema_d_dataset.head())\n",
    "\n",
    "# Check the dataset's structure\n",
    "print(crema_d_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7442, 67)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_d_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVEE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9s/3d7b5lt55zggdrplnwwbsq_40000gp/T/ipykernel_16533/2854502561.py:98: FutureWarning: librosa.beat.tempo\n",
      "\tThis function was moved to 'librosa.feature.rhythm.tempo' in librosa version 0.10.0.\n",
      "\tThis alias will be removed in librosa version 1.0.\n",
      "  tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr).item()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVEE feature extraction completed and dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Define target duration (in seconds) and sampling rate\n",
    "target_duration = 3.0  # in seconds\n",
    "target_sampling_rate = 22050  # in Hz\n",
    "\n",
    "# Unified emotion mapping\n",
    "emotion_mapping = {\n",
    "    \"n\": \"neutral\",\n",
    "    \"h\": \"happy\",\n",
    "    \"sa\": \"sad\",\n",
    "    \"a\": \"angry\",\n",
    "    \"f\": \"fearful\",\n",
    "    \"d\": \"disgust\",\n",
    "    \"su\": \"surprised\"\n",
    "}\n",
    "\n",
    "# Function to preprocess audio file to ensure consistent duration and sampling rate\n",
    "def preprocess_audio(audio_path):\n",
    "    audio, sr = librosa.load(audio_path, sr=target_sampling_rate)\n",
    "    target_length = int(target_duration * target_sampling_rate)\n",
    "\n",
    "    if len(audio) < target_length:\n",
    "        # Pad with zeros to reach the target length\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "    else:\n",
    "        # Truncate to the target length\n",
    "        audio = audio[:target_length]\n",
    "\n",
    "    return audio, target_sampling_rate\n",
    "\n",
    "# Function to extract features from a single audio file\n",
    "def extract_features(audio_path):\n",
    "    features = {}\n",
    "\n",
    "    # Preprocess the audio file\n",
    "    audio, sr = preprocess_audio(audio_path)\n",
    "\n",
    "    # --- Features from your notebook ---\n",
    "    FRAME_LENGTH = 1024\n",
    "    HOP_LENGTH = 512\n",
    "\n",
    "    # 1. RMSE\n",
    "    rms = librosa.feature.rms(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).mean()\n",
    "    features['RMSE'] = rms\n",
    "\n",
    "    # 2. Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH).mean()\n",
    "    features['Zero_Crossing_Rate'] = zcr\n",
    "\n",
    "    # 3. Mel Spectrogram\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH, n_mels=90)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec).mean()\n",
    "    features['Mel_Spectrogram_Mean'] = mel_spec_db\n",
    "\n",
    "    # 4. MFCCs and derivatives\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13, n_fft=1024, hop_length=HOP_LENGTH)\n",
    "    mfccs_mean = mfccs.mean(axis=1)\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "    features.update({f'MFCC_{i+1}': val for i, val in enumerate(mfccs_mean)})\n",
    "    features.update({f'Delta_MFCC_{i+1}': val for i, val in enumerate(delta_mfccs.mean(axis=1))})\n",
    "    features.update({f'Delta2_MFCC_{i+1}': val for i, val in enumerate(delta2_mfccs.mean(axis=1))})\n",
    "\n",
    "    # 5. Spectral Centroid\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Centroid'] = spectral_centroid\n",
    "\n",
    "    # 6. Spectral Bandwidth\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Bandwidth'] = spectral_bandwidth\n",
    "\n",
    "    # --- Additional Features ---\n",
    "    # 7. Pitch (Fundamental Frequency)\n",
    "    pitches, magnitudes = librosa.piptrack(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH)\n",
    "    pitch_mean = np.mean(pitches[pitches > 0]) if np.any(pitches > 0) else 0\n",
    "    features['Pitch_Mean'] = pitch_mean\n",
    "\n",
    "    # 8. Harmonic-to-Noise Ratio (HNR)\n",
    "    harmonic, percussive = librosa.effects.hpss(audio)\n",
    "    hnr = 10 * np.log10(np.mean(harmonic**2) / np.mean(percussive**2)) if np.mean(percussive**2) > 0 else 0\n",
    "    features['HNR'] = hnr\n",
    "\n",
    "    # 9. Spectral Contrast\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Contrast'] = spectral_contrast\n",
    "\n",
    "    # 10. Chroma Features\n",
    "    chroma = librosa.feature.chroma_stft(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean(axis=1)\n",
    "    features.update({f'Chroma_{i+1}': val for i, val in enumerate(chroma)})\n",
    "\n",
    "    # 11. Tempo (Rhythm)\n",
    "    onset_env = librosa.onset.onset_strength(y=audio, sr=sr, hop_length=HOP_LENGTH)\n",
    "    tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr).item()\n",
    "    features['Tempo'] = tempo\n",
    "\n",
    "    # 12. Jitter and Shimmer (Approximation)\n",
    "    jitter = np.std(np.diff(pitches[pitches > 0])) / pitch_mean if pitch_mean > 0 else 0\n",
    "    shimmer = np.std(np.abs(np.diff(audio))) / np.mean(np.abs(audio)) if np.mean(np.abs(audio)) > 0 else 0\n",
    "    features['Jitter'] = jitter\n",
    "    features['Shimmer'] = shimmer\n",
    "\n",
    "    # 13. Tonality and Timbre\n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=audio).mean()\n",
    "    features['Spectral_Flatness'] = spectral_flatness\n",
    "\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, n_fft=1024, hop_length=HOP_LENGTH).mean()\n",
    "    features['Spectral_Rolloff'] = spectral_rolloff\n",
    "\n",
    "    # 14. Duration and Silence\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "    silence = np.mean(audio == 0)\n",
    "    features['Duration'] = duration\n",
    "    features['Silence'] = silence\n",
    "\n",
    "    return features\n",
    "\n",
    "# Function to process all audio files in the SAVEE dataset\n",
    "def process_savee(dataset_path):\n",
    "    data = []\n",
    "\n",
    "    for root, _, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                # Extract emotion from filename (e.g., \"JK_su01.wav\")\n",
    "                file_parts = file.split('_')\n",
    "                emotion_code = file_parts[1][:2]  # Get the emotion code (e.g., 'su', 'sa')\n",
    "                emotion = emotion_mapping.get(emotion_code, \"unknown\")\n",
    "\n",
    "                features = extract_features(file_path)\n",
    "                features['Emotion'] = emotion\n",
    "                data.append(features)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Path to SAVEE dataset\n",
    "dataset_path = \"Dataset/SAVEE\"\n",
    "savee_dataset = process_savee(dataset_path)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "savee_dataset.to_csv(\"Dataset/SAVEE_features_dataset.csv\", index=False)\n",
    "\n",
    "print(\"SAVEE feature extraction completed and dataset saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RMSE  Zero_Crossing_Rate  Mel_Spectrogram_Mean      MFCC_1      MFCC_2  \\\n",
      "0  0.096243            0.019524            -35.962654 -408.271881  101.782509   \n",
      "1  0.073336            0.014979            -37.673794 -432.946167  121.255760   \n",
      "2  0.061558            0.011208            -44.537773 -506.484436  120.200455   \n",
      "3  0.134778            0.019028            -35.241142 -403.779358   98.904404   \n",
      "4  0.072211            0.016677            -41.526272 -471.727753  145.821045   \n",
      "\n",
      "      MFCC_3     MFCC_4     MFCC_5     MFCC_6     MFCC_7  ...  Chroma_11  \\\n",
      "0  14.735724  57.775494  -3.375690 -10.940758   5.251171  ...   0.478388   \n",
      "1   9.786642  53.720806  16.386436 -15.011709   0.361910  ...   0.629491   \n",
      "2  28.003235  27.287685  18.309204   5.175481 -11.274021  ...   0.558801   \n",
      "3  18.473347  35.634796  -1.421025   7.098048 -27.093967  ...   0.529298   \n",
      "4  22.681051  37.001007  30.451714  -8.311298 -17.866390  ...   0.553176   \n",
      "\n",
      "   Chroma_12       Tempo    Jitter   Shimmer  Spectral_Flatness  \\\n",
      "0   0.523819  135.999178  0.055533  0.222115           0.000232   \n",
      "1   0.616367  103.359375  0.042323  0.176567           0.000079   \n",
      "2   0.532814  172.265625  0.057736  0.127035           0.054705   \n",
      "3   0.492462  129.199219  0.089785  0.179225           0.000228   \n",
      "4   0.526567   99.384014  0.033529  0.146693           0.000035   \n",
      "\n",
      "   Spectral_Rolloff  Duration  Silence    Emotion  \n",
      "0       1972.938326       3.0  0.00000        sad  \n",
      "1       1514.115460       3.0  0.00000        sad  \n",
      "2       1000.962665       3.0  0.07037    unknown  \n",
      "3       1810.279823       3.0  0.00000  surprised  \n",
      "4        964.190580       3.0  0.00000    unknown  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 480 entries, 0 to 479\n",
      "Data columns (total 67 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   RMSE                  480 non-null    float32\n",
      " 1   Zero_Crossing_Rate    480 non-null    float64\n",
      " 2   Mel_Spectrogram_Mean  480 non-null    float32\n",
      " 3   MFCC_1                480 non-null    float32\n",
      " 4   MFCC_2                480 non-null    float32\n",
      " 5   MFCC_3                480 non-null    float32\n",
      " 6   MFCC_4                480 non-null    float32\n",
      " 7   MFCC_5                480 non-null    float32\n",
      " 8   MFCC_6                480 non-null    float32\n",
      " 9   MFCC_7                480 non-null    float32\n",
      " 10  MFCC_8                480 non-null    float32\n",
      " 11  MFCC_9                480 non-null    float32\n",
      " 12  MFCC_10               480 non-null    float32\n",
      " 13  MFCC_11               480 non-null    float32\n",
      " 14  MFCC_12               480 non-null    float32\n",
      " 15  MFCC_13               480 non-null    float32\n",
      " 16  Delta_MFCC_1          480 non-null    float32\n",
      " 17  Delta_MFCC_2          480 non-null    float32\n",
      " 18  Delta_MFCC_3          480 non-null    float32\n",
      " 19  Delta_MFCC_4          480 non-null    float32\n",
      " 20  Delta_MFCC_5          480 non-null    float32\n",
      " 21  Delta_MFCC_6          480 non-null    float32\n",
      " 22  Delta_MFCC_7          480 non-null    float32\n",
      " 23  Delta_MFCC_8          480 non-null    float32\n",
      " 24  Delta_MFCC_9          480 non-null    float32\n",
      " 25  Delta_MFCC_10         480 non-null    float32\n",
      " 26  Delta_MFCC_11         480 non-null    float32\n",
      " 27  Delta_MFCC_12         480 non-null    float32\n",
      " 28  Delta_MFCC_13         480 non-null    float32\n",
      " 29  Delta2_MFCC_1         480 non-null    float32\n",
      " 30  Delta2_MFCC_2         480 non-null    float32\n",
      " 31  Delta2_MFCC_3         480 non-null    float32\n",
      " 32  Delta2_MFCC_4         480 non-null    float32\n",
      " 33  Delta2_MFCC_5         480 non-null    float32\n",
      " 34  Delta2_MFCC_6         480 non-null    float32\n",
      " 35  Delta2_MFCC_7         480 non-null    float32\n",
      " 36  Delta2_MFCC_8         480 non-null    float32\n",
      " 37  Delta2_MFCC_9         480 non-null    float32\n",
      " 38  Delta2_MFCC_10        480 non-null    float32\n",
      " 39  Delta2_MFCC_11        480 non-null    float32\n",
      " 40  Delta2_MFCC_12        480 non-null    float32\n",
      " 41  Delta2_MFCC_13        480 non-null    float32\n",
      " 42  Spectral_Centroid     480 non-null    float64\n",
      " 43  Spectral_Bandwidth    480 non-null    float64\n",
      " 44  Pitch_Mean            480 non-null    float32\n",
      " 45  HNR                   480 non-null    float64\n",
      " 46  Spectral_Contrast     480 non-null    float64\n",
      " 47  Chroma_1              480 non-null    float32\n",
      " 48  Chroma_2              480 non-null    float32\n",
      " 49  Chroma_3              480 non-null    float32\n",
      " 50  Chroma_4              480 non-null    float32\n",
      " 51  Chroma_5              480 non-null    float32\n",
      " 52  Chroma_6              480 non-null    float32\n",
      " 53  Chroma_7              480 non-null    float32\n",
      " 54  Chroma_8              480 non-null    float32\n",
      " 55  Chroma_9              480 non-null    float32\n",
      " 56  Chroma_10             480 non-null    float32\n",
      " 57  Chroma_11             480 non-null    float32\n",
      " 58  Chroma_12             480 non-null    float32\n",
      " 59  Tempo                 480 non-null    float64\n",
      " 60  Jitter                480 non-null    float32\n",
      " 61  Shimmer               480 non-null    float32\n",
      " 62  Spectral_Flatness     480 non-null    float32\n",
      " 63  Spectral_Rolloff      480 non-null    float64\n",
      " 64  Duration              480 non-null    float64\n",
      " 65  Silence               480 non-null    float64\n",
      " 66  Emotion               480 non-null    object \n",
      "dtypes: float32(57), float64(9), object(1)\n",
      "memory usage: 144.5+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(480, 67)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "savee_dataset_path = 'Dataset/SAVEE_features_dataset.csv'  # Replace with your file path\n",
    "saveee_dataset = pd.read_csv(savee_dataset_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(savee_dataset.head())\n",
    "\n",
    "# Check the dataset's structure\n",
    "print(savee_dataset.info())\n",
    "\n",
    "saveee_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
